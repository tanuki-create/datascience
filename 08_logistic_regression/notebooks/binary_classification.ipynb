{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 二値分類の実践例\n",
        "\n",
        "このノートブックでは、実際のデータセットを使用してロジスティック回帰による二値分類を実践します。\n",
        "\n",
        "## 学習目標\n",
        "- 実データでのロジスティック回帰の適用\n",
        "- データの前処理と特徴量エンジニアリング\n",
        "- モデルの評価と解釈\n",
        "- ビジネス応用の理解\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
        "                           f1_score, roc_auc_score, roc_curve, confusion_matrix,\n",
        "                           classification_report)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 日本語フォントの設定\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. データセットの読み込み\n",
        "\n",
        "乳がんデータセットを使用して、悪性（malignant）と良性（benign）の分類を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 乳がんデータセットの読み込み\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# データフレームの作成\n",
        "df = pd.DataFrame(X, columns=cancer.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(\"=== データセットの基本情報 ===\")\n",
        "print(f\"データの形状: {X.shape}\")\n",
        "print(f\"特徴量の数: {X.shape[1]}\")\n",
        "print(f\"サンプル数: {X.shape[0]}\")\n",
        "print(f\"クラスの分布: {np.bincount(y)}\")\n",
        "print(f\"クラス名: {cancer.target_names}\")\n",
        "\n",
        "# データの可視化（最初の2つの特徴量）\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', label='Malignant', alpha=0.7)\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', label='Benign', alpha=0.7)\n",
        "plt.xlabel(cancer.feature_names[0])\n",
        "plt.ylabel(cancer.feature_names[1])\n",
        "plt.title('Breast Cancer Dataset - First Two Features')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# データの基本統計\n",
        "print(\"\\n=== データの基本統計 ===\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. データの前処理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 特徴量の標準化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"=== データ分割の結果 ===\")\n",
        "print(f\"訓練データの形状: {X_train_scaled.shape}\")\n",
        "print(f\"テストデータの形状: {X_test_scaled.shape}\")\n",
        "print(f\"訓練データのクラス分布: {np.bincount(y_train)}\")\n",
        "print(f\"テストデータのクラス分布: {np.bincount(y_test)}\")\n",
        "\n",
        "# 標準化前後の比較\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(X_train[:, 0], bins=30, alpha=0.7, label='Original')\n",
        "plt.title('Original Data - First Feature')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.hist(X_train_scaled[:, 0], bins=30, alpha=0.7, label='Scaled', color='orange')\n",
        "plt.title('Scaled Data - First Feature')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.boxplot([X_train[:, 0], X_train_scaled[:, 0]], labels=['Original', 'Scaled'])\n",
        "plt.title('Box Plot Comparison')\n",
        "plt.ylabel('Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. モデルの訓練と評価\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ロジスティック回帰モデルの訓練\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 予測\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 基本的な評価指標\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"=== モデルの評価結果 ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# 混同行列の可視化\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Malignant', 'Benign'], \n",
        "            yticklabels=['Malignant', 'Benign'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# ROC曲線の描画\n",
        "plt.subplot(1, 2, 2)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 分類レポート\n",
        "print(\"\\n=== 詳細な分類レポート ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 特徴量の重要度分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量の重要度（係数の絶対値）\n",
        "feature_importance = np.abs(model.coef_[0])\n",
        "feature_names = cancer.feature_names\n",
        "\n",
        "# 重要度の順位付け\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance,\n",
        "    'coefficient': model.coef_[0]\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"=== 特徴量の重要度（上位10位） ===\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# 重要度の可視化\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = importance_df.head(15)\n",
        "plt.barh(range(len(top_features)), top_features['importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Feature Importance (|Coefficient|)')\n",
        "plt.title('Top 15 Most Important Features')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 係数の分布\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(model.coef_[0], bins=20, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Coefficients')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(range(len(model.coef_[0])), model.coef_[0], alpha=0.7)\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.title('Coefficients by Feature Index')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ハイパーパラメータの最適化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# グリッドサーチによるハイパーパラメータの最適化\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=1000),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"=== グリッドサーチの結果 ===\")\n",
        "print(f\"最良のパラメータ: {grid_search.best_params_}\")\n",
        "print(f\"最良のスコア: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 最良のモデルで予測\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "y_pred_proba_best = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# 最適化後の評価\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
        "\n",
        "print(f\"\\n=== 最適化後の評価 ===\")\n",
        "print(f\"Accuracy: {accuracy_best:.4f}\")\n",
        "print(f\"AUC: {auc_best:.4f}\")\n",
        "\n",
        "# 正則化パラメータCの影響を可視化\n",
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "train_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, random_state=42, max_iter=1000)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    train_score = roc_auc_score(y_train, model.predict_proba(X_train_scaled)[:, 1])\n",
        "    val_score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc').mean()\n",
        "    \n",
        "    train_scores.append(train_score)\n",
        "    val_scores.append(val_score)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(C_values, train_scores, 'o-', label='Training Score')\n",
        "plt.plot(C_values, val_scores, 'o-', label='Validation Score')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Regularization Parameter (C)')\n",
        "plt.ylabel('ROC AUC Score')\n",
        "plt.title('Effect of Regularization Parameter C')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ビジネス応用の考察\n",
        "\n",
        "### 6.1 医療診断における解釈\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 予測確率の分布と解釈\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.hist(y_pred_proba_best[y_test == 0], bins=20, alpha=0.7, label='Malignant', color='red')\n",
        "plt.hist(y_pred_proba_best[y_test == 1], bins=20, alpha=0.7, label='Benign', color='blue')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Predicted Probabilities')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "# 信頼度の高い予測（確率が0.8以上または0.2以下）\n",
        "high_confidence = (y_pred_proba_best >= 0.8) | (y_pred_proba_best <= 0.2)\n",
        "plt.scatter(y_pred_proba_best[high_confidence], y_test[high_confidence], \n",
        "           c='green', alpha=0.7, label='High Confidence')\n",
        "plt.scatter(y_pred_proba_best[~high_confidence], y_test[~high_confidence], \n",
        "           c='orange', alpha=0.7, label='Low Confidence')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Prediction Confidence')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "# 誤分類の分析\n",
        "misclassified = (y_pred_best != y_test)\n",
        "plt.scatter(y_pred_proba_best[~misclassified], y_test[~misclassified], \n",
        "           c='green', alpha=0.7, label='Correct')\n",
        "plt.scatter(y_pred_proba_best[misclassified], y_test[misclassified], \n",
        "           c='red', alpha=0.7, label='Misclassified')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Classification Results')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 信頼度の統計\n",
        "print(\"=== 予測の信頼度分析 ===\")\n",
        "print(f\"高信頼度予測の割合: {np.mean(high_confidence):.2%}\")\n",
        "print(f\"高信頼度予測の精度: {accuracy_score(y_test[high_confidence], y_pred_best[high_confidence]):.4f}\")\n",
        "print(f\"低信頼度予測の精度: {accuracy_score(y_test[~high_confidence], y_pred_best[~high_confidence]):.4f}\")\n",
        "\n",
        "# 誤分類の詳細分析\n",
        "print(f\"\\n=== 誤分類の分析 ===\")\n",
        "print(f\"誤分類数: {np.sum(misclassified)}\")\n",
        "print(f\"誤分類率: {np.mean(misclassified):.2%}\")\n",
        "print(f\"誤分類の平均確率: {np.mean(y_pred_proba_best[misclassified]):.4f}\")\n",
        "print(f\"正分類の平均確率: {np.mean(y_pred_proba_best[~misclassified]):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 演習問題\n",
        "\n",
        "### 演習1: 特徴量選択\n",
        "上位10個の特徴量のみを使用してモデルを再訓練し、性能を比較してみましょう。\n",
        "\n",
        "### 演習2: 決定閾値の調整\n",
        "医療診断では、False Negative（見逃し）を避けることが重要です。Recallを最大化する閾値を探してみましょう。\n",
        "\n",
        "### 演習3: クラス不均衡の対処\n",
        "データセットのクラス分布を変更して、不均衡データに対する対策を実装してみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、乳がんデータセットを使用してロジスティック回帰による二値分類を実践しました。\n",
        "\n",
        "**学習した内容**：\n",
        "- 実データでのロジスティック回帰の適用\n",
        "- データの前処理と特徴量の標準化\n",
        "- モデルの評価と解釈\n",
        "- ハイパーパラメータの最適化\n",
        "- 特徴量の重要度分析\n",
        "- ビジネス応用における解釈\n",
        "\n",
        "**重要なポイント**：\n",
        "- 医療診断では確率的な出力が重要\n",
        "- 特徴量の標準化が性能に大きく影響\n",
        "- 正則化パラメータの調整が重要\n",
        "- 解釈可能性が実務では重要\n",
        "\n",
        "**次のステップ**：\n",
        "- 多クラス分類への拡張\n",
        "- より高度な特徴量エンジニアリング\n",
        "- アンサンブル手法の学習\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
