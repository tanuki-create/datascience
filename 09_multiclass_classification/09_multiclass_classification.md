# 多クラス分類

## 概要

多クラス分類は、3つ以上のクラスにデータを分類する問題です。二値分類の手法を拡張して、複数のクラスを扱うための様々なアプローチが存在します。

## 1. 多クラス分類とは

### 1.1 二値分類との違い

**二値分類**：
- 2つのクラス（例：スパム/非スパム）
- 出力：0または1
- 確率：P(y=1|x)

**多クラス分類**：
- 3つ以上のクラス（例：手書き数字0-9、動物分類）
- 出力：0, 1, 2, ..., K-1
- 確率：P(y=k|x) for k=0,1,...,K-1

### 1.2 多クラス分類のアプローチ

**1. One-vs-Rest (OvR)**：
- 各クラスに対して二値分類器を訓練
- K個のクラスに対してK個の分類器

**2. One-vs-One (OvO)**：
- クラスのペアごとに二値分類器を訓練
- K個のクラスに対してK(K-1)/2個の分類器

**3. 多項ロジスティック回帰**：
- ソフトマックス関数を使用
- 1つのモデルで全クラスを同時に扱う

## 2. One-vs-Rest (OvR) アプローチ

### 2.1 基本概念

One-vs-Restは、多クラス分類を複数の二値分類問題に分解する手法です。

**アルゴリズム**：
1. 各クラスkに対して、クラスk vs その他のクラスで二値分類器を訓練
2. 新しいサンプルに対して、各分類器の確率を計算
3. 最も高い確率を持つクラスを選択

### 2.2 数式表現

**K個のクラスに対するOvR**：
```
f₁(x) = P(y=1|x)
f₂(x) = P(y=2|x)
...
fₖ(x) = P(y=K|x)
```

**予測ルール**：
```
ŷ = argmaxₖ fₖ(x)
```

### 2.3 利点と欠点

**利点**：
- 実装が簡単
- 既存の二値分類器を再利用可能
- 計算効率が良い

**欠点**：
- クラス不均衡の問題
- 確率の正規化が必要
- 決定境界が複雑になる場合がある

## 3. One-vs-One (OvO) アプローチ

### 3.1 基本概念

One-vs-Oneは、クラスのペアごとに二値分類器を訓練する手法です。

**アルゴリズム**：
1. 各クラスペア(i,j)に対して、クラスi vs クラスjで二値分類器を訓練
2. 新しいサンプルに対して、各分類器の予測を収集
3. 投票により最終的なクラスを決定

### 3.2 数式表現

**K個のクラスに対するOvO**：
- 必要な分類器数：K(K-1)/2
- 各分類器：fᵢⱼ(x) = P(y=i|y∈{i,j}, x)

**投票ルール**：
```
ŷ = argmaxₖ Σⱼ≠ₖ voteₖⱼ
```

### 3.3 利点と欠点

**利点**：
- クラス不均衡の影響が少ない
- より細かい決定境界
- 確率の正規化が不要

**欠点**：
- 分類器数が多くなる（O(K²)）
- 計算コストが高い
- 実装が複雑

## 4. 多項ロジスティック回帰

### 4.1 ソフトマックス関数

多項ロジスティック回帰では、ソフトマックス関数を使用して確率を計算します。

**ソフトマックス関数**：
```
σ(z)ᵢ = exp(zᵢ) / Σⱼ₌₁ᴷ exp(zⱼ)
```

**特徴**：
- 出力の合計が1になる
- すべての出力が正の値
- 指数関数により大きな値が強調される

### 4.2 多項ロジスティック回帰の数式

**線形結合**：
```
zᵢ = wᵢ₀ + wᵢ₁x₁ + wᵢ₂x₂ + ... + wᵢₙxₙ
```

**確率の計算**：
```
P(y=k|x) = exp(zₖ) / Σⱼ₌₁ᴷ exp(zⱼ)
```

**損失関数（交差エントロピー）**：
```
L = -Σᵢ₌₁ᵐ Σₖ₌₁ᴷ yᵢₖ log(P(y=k|xᵢ))
```

### 4.3 勾配の計算

**重みの勾配**：
```
∂L/∂wₖⱼ = Σᵢ₌₁ᵐ (P(y=k|xᵢ) - yᵢₖ) xᵢⱼ
```

**バイアスの勾配**：
```
∂L/∂bₖ = Σᵢ₌₁ᵐ (P(y=k|xᵢ) - yᵢₖ)
```

## 5. 実装の詳細

### 5.1 データの前処理

**ラベルのエンコーディング**：
- 文字列ラベルを数値に変換
- 例：['cat', 'dog', 'bird'] → [0, 1, 2]

**特徴量の標準化**：
- 多クラス分類でも標準化が重要
- StandardScalerやMinMaxScalerの使用

### 5.2 モデルの選択

**OvR vs OvO vs 多項ロジスティック回帰**：

| 手法 | 分類器数 | 計算効率 | 精度 | 実装の複雑さ |
|------|----------|----------|------|--------------|
| OvR | K | 高い | 中程度 | 簡単 |
| OvO | K(K-1)/2 | 低い | 高い | 複雑 |
| 多項 | 1 | 中程度 | 高い | 中程度 |

### 5.3 ハイパーパラメータ

**正則化**：
- L1正則化：特徴選択効果
- L2正則化：過学習防止
- Elastic Net：L1とL2の組み合わせ

**ソルバーの選択**：
- liblinear：小規模データ、L1正則化
- lbfgs：中規模データ、L2正則化
- sag：大規模データ、L2正則化

## 6. 評価指標

### 6.1 基本的な指標

**Accuracy（正解率）**：
```
Accuracy = (正解数) / (全サンプル数)
```

**Macro平均**：
```
Macro-Precision = (1/K) Σₖ₌₁ᴷ Precisionₖ
Macro-Recall = (1/K) Σₖ₌₁ᴷ Recallₖ
Macro-F1 = (1/K) Σₖ₌₁ᴷ F1ₖ
```

**Micro平均**：
```
Micro-Precision = Micro-Recall = Micro-F1 = Accuracy
```

### 6.2 混同行列

**K×K混同行列**：
```
       予測
    0  1  2  ...  K-1
実 0
際 1
   2
   ...
   K-1
```

### 6.3 クラス別の評価

**各クラスのPrecision、Recall、F1-score**：
- クラスkのPrecision：TPₖ / (TPₖ + FPₖ)
- クラスkのRecall：TPₖ / (TPₖ + FNₖ)
- クラスkのF1-score：2 × Precisionₖ × Recallₖ / (Precisionₖ + Recallₖ)

## 7. 実務での応用

### 7.1 画像認識

**手書き数字認識**：
- 入力：28×28ピクセルの画像
- 出力：0-9の数字
- 手法：多項ロジスティック回帰、CNN

**物体認識**：
- 入力：画像
- 出力：物体のクラス（猫、犬、鳥など）
- 手法：CNN、転移学習

### 7.2 自然言語処理

**文書分類**：
- 入力：文書の特徴量
- 出力：カテゴリ（スポーツ、政治、経済など）
- 手法：多項ロジスティック回帰、SVM

**感情分析**：
- 入力：テキスト
- 出力：感情（ポジティブ、ネガティブ、ニュートラル）
- 手法：多項ロジスティック回帰、LSTM

### 7.3 推薦システム

**商品推薦**：
- 入力：ユーザー特徴量、商品特徴量
- 出力：商品カテゴリ
- 手法：多項ロジスティック回帰、協調フィルタリング

## 8. よくある落とし穴と注意点

### 8.1 クラス不均衡

**問題**：
- 一部のクラスのサンプル数が極端に少ない
- 少数クラスの予測精度が低下

**対策**：
- クラス重みの調整
- SMOTE（合成少数オーバーサンプリング）
- コスト感度学習

### 8.2 特徴量の選択

**問題**：
- 無関係な特徴量の混入
- 次元の呪い

**対策**：
- 特徴量重要度の確認
- 次元削減手法の適用
- 正則化の使用

### 8.3 モデルの解釈

**問題**：
- 複雑なモデルの解釈が困難
- ビジネス要件との整合性

**対策**：
- 特徴量重要度の可視化
- 決定境界の可視化
- 予測確率の解釈

## 9. 高度な手法

### 9.1 アンサンブル手法

**投票法**：
- 複数のモデルの予測を組み合わせ
- ハード投票、ソフト投票

**スタッキング**：
- メタ学習器で予測を組み合わせ
- より複雑だが高精度

### 9.2 深層学習

**多層パーセプトロン**：
- 隠れ層を持つニューラルネットワーク
- 非線形な決定境界

**CNN**：
- 画像データに特化
- 畳み込み層による特徴抽出

**RNN**：
- 時系列データに特化
- 再帰的な構造

## 10. まとめ

多クラス分類は、機械学習の重要な分野です。適切な手法の選択と実装により、実務での様々な問題を解決できます。

**主なポイント**：
- OvR、OvO、多項ロジスティック回帰の使い分け
- 適切な評価指標の選択
- クラス不均衡への対処
- 特徴量エンジニアリングの重要性

**次のステップ**：
- より高度な分類手法の学習
- 深層学習の応用
- 実務での応用事例の学習

## 関連トピック

- [分類評価指標](../10_classification_metrics/10_classification_metrics.md)
- [ROC/AUC](../11_roc_auc/11_roc_auc.md)
- [主成分分析](../12_pca/12_pca.md)
