{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# One-vs-Rest (OvR) の実装\n",
        "\n",
        "このノートブックでは、One-vs-Restアプローチを使用した多クラス分類を実装します。\n",
        "\n",
        "## 学習目標\n",
        "- One-vs-Restアプローチの理解\n",
        "- 複数の二値分類器の組み合わせ\n",
        "- 多クラス分類の評価\n",
        "- 決定境界の可視化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import (accuracy_score, classification_report, \n",
        "                           confusion_matrix, roc_curve, auc)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 日本語フォントの設定\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. データの準備\n",
        "\n",
        "多クラス分類用のデータセットを生成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 多クラス分類用のデータセットを生成\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=2,\n",
        "    n_redundant=0,\n",
        "    n_informative=2,\n",
        "    n_clusters_per_class=1,\n",
        "    n_classes=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# データの可視化\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = ['red', 'blue', 'green']\n",
        "labels = ['Class 0', 'Class 1', 'Class 2']\n",
        "\n",
        "for i in range(3):\n",
        "    plt.scatter(X[y == i, 0], X[y == i, 1], c=colors[i], label=labels[i], alpha=0.7)\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Multi-class Classification Dataset')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"データセットの形状: {X.shape}\")\n",
        "print(f\"クラスの分布: {np.bincount(y)}\")\n",
        "print(f\"クラス数: {len(np.unique(y))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 特徴量の標準化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"=== データ分割の結果 ===\")\n",
        "print(f\"訓練データの形状: {X_train_scaled.shape}\")\n",
        "print(f\"テストデータの形状: {X_test_scaled.shape}\")\n",
        "print(f\"訓練データのクラス分布: {np.bincount(y_train)}\")\n",
        "print(f\"テストデータのクラス分布: {np.bincount(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. One-vs-Restの実装\n",
        "\n",
        "### 2.1 手動実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OneVsRestClassifier:\n",
        "    \"\"\"\n",
        "    One-vs-Rest分類器の手動実装\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, base_classifier):\n",
        "        \"\"\"\n",
        "        パラメータの初期化\n",
        "        \n",
        "        Parameters:\n",
        "        base_classifier: 基底となる二値分類器\n",
        "        \"\"\"\n",
        "        self.base_classifier = base_classifier\n",
        "        self.classifiers = []\n",
        "        self.classes = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        モデルの訓練\n",
        "        \n",
        "        Parameters:\n",
        "        X: 特徴量\n",
        "        y: ラベル\n",
        "        \"\"\"\n",
        "        self.classes = np.unique(y)\n",
        "        self.classifiers = []\n",
        "        \n",
        "        # 各クラスに対して二値分類器を訓練\n",
        "        for class_label in self.classes:\n",
        "            # 現在のクラス vs その他のクラスで二値分類\n",
        "            y_binary = (y == class_label).astype(int)\n",
        "            \n",
        "            # 分類器をコピーして訓練\n",
        "            classifier = type(self.base_classifier)(**self.base_classifier.get_params())\n",
        "            classifier.fit(X, y_binary)\n",
        "            self.classifiers.append(classifier)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        確率の予測\n",
        "        \n",
        "        Parameters:\n",
        "        X: 特徴量\n",
        "        \n",
        "        Returns:\n",
        "        probabilities: 予測確率\n",
        "        \"\"\"\n",
        "        probabilities = []\n",
        "        \n",
        "        for classifier in self.classifiers:\n",
        "            # 各分類器の確率を取得\n",
        "            prob = classifier.predict_proba(X)[:, 1]\n",
        "            probabilities.append(prob)\n",
        "        \n",
        "        # 確率の正規化\n",
        "        probabilities = np.array(probabilities).T\n",
        "        probabilities = probabilities / probabilities.sum(axis=1, keepdims=True)\n",
        "        \n",
        "        return probabilities\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        クラスの予測\n",
        "        \n",
        "        Parameters:\n",
        "        X: 特徴量\n",
        "        \n",
        "        Returns:\n",
        "        predictions: 予測クラス\n",
        "        \"\"\"\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return self.classes[np.argmax(probabilities, axis=1)]\n",
        "\n",
        "# 手動実装のテスト\n",
        "base_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
        "ovr_manual = OneVsRestClassifier(base_classifier)\n",
        "ovr_manual.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 予測\n",
        "y_pred_manual = ovr_manual.predict(X_test_scaled)\n",
        "y_pred_proba_manual = ovr_manual.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"=== 手動実装の結果 ===\")\n",
        "print(f\"予測クラス: {y_pred_manual[:10]}\")\n",
        "print(f\"予測確率の形状: {y_pred_proba_manual.shape}\")\n",
        "print(f\"予測確率の合計: {y_pred_proba_manual.sum(axis=1)[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 scikit-learnの実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scikit-learnのOneVsRestClassifier\n",
        "ovr_sklearn = OneVsRestClassifier(LogisticRegression(random_state=42, max_iter=1000))\n",
        "ovr_sklearn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 予測\n",
        "y_pred_sklearn = ovr_sklearn.predict(X_test_scaled)\n",
        "y_pred_proba_sklearn = ovr_sklearn.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"=== scikit-learnの実装結果 ===\")\n",
        "print(f\"予測クラス: {y_pred_sklearn[:10]}\")\n",
        "print(f\"予測確率の形状: {y_pred_proba_sklearn.shape}\")\n",
        "print(f\"予測確率の合計: {y_pred_proba_sklearn.sum(axis=1)[:5]}\")\n",
        "\n",
        "# 手動実装とscikit-learnの比較\n",
        "print(f\"\\n=== 実装の比較 ===\")\n",
        "print(f\"手動実装の精度: {accuracy_score(y_test, y_pred_manual):.4f}\")\n",
        "print(f\"scikit-learnの精度: {accuracy_score(y_test, y_pred_sklearn):.4f}\")\n",
        "print(f\"予測の一致率: {np.mean(y_pred_manual == y_pred_sklearn):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 決定境界の可視化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
        "    \"\"\"\n",
        "    決定境界の可視化\n",
        "    \n",
        "    Parameters:\n",
        "    model: 訓練済みモデル\n",
        "    X: 特徴量\n",
        "    y: ラベル\n",
        "    title: グラフのタイトル\n",
        "    \"\"\"\n",
        "    # メッシュグリッドの作成\n",
        "    h = 0.01\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    \n",
        "    # 予測\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    \n",
        "    # プロット\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.contourf(xx, yy, Z, levels=2, alpha=0.8, colors=['red', 'blue', 'green'])\n",
        "    \n",
        "    # データポイントのプロット\n",
        "    colors = ['red', 'blue', 'green']\n",
        "    labels = ['Class 0', 'Class 1', 'Class 2']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.scatter(X[y == i, 0], X[y == i, 1], c=colors[i], label=labels[i], \n",
        "                   alpha=0.7, edgecolors='black', linewidth=1)\n",
        "    \n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# 決定境界の可視化\n",
        "plot_decision_boundary(ovr_sklearn, X_train_scaled, y_train, \"One-vs-Rest Decision Boundary\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. モデルの評価\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 精度の計算\n",
        "accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(\"=== モデルの評価結果 ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 混同行列の可視化\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Class 0', 'Class 1', 'Class 2'], \n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# 分類レポート\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.text(0.1, 0.9, 'Classification Report:', fontsize=14, fontweight='bold', transform=plt.gca().transAxes)\n",
        "plt.text(0.1, 0.8, classification_report(y_test, y_pred_sklearn, target_names=['Class 0', 'Class 1', 'Class 2']), \n",
        "         fontsize=10, transform=plt.gca().transAxes, verticalalignment='top')\n",
        "plt.axis('off')\n",
        "plt.title('Classification Report')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 各クラスのROC曲線\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i in range(3):\n",
        "    # クラスiの二値分類として扱う\n",
        "    y_binary = (y_test == i).astype(int)\n",
        "    y_proba = y_pred_proba_sklearn[:, i]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(y_binary, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for Class {i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 演習問題\n",
        "\n",
        "### 演習1: クラス数の影響\n",
        "異なるクラス数（4, 5, 6クラス）でデータセットを生成し、One-vs-Restの性能を比較してみましょう。\n",
        "\n",
        "### 演習2: 基底分類器の比較\n",
        "異なる基底分類器（SVM、決定木など）を使用して、One-vs-Restの性能を比較してみましょう。\n",
        "\n",
        "### 演習3: 確率の正規化\n",
        "確率の正規化を行わない場合と行う場合の性能の違いを確認してみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、One-vs-Restアプローチを使用した多クラス分類を実装しました。\n",
        "\n",
        "**学習した内容**：\n",
        "- One-vs-Restアプローチの理論と実装\n",
        "- 複数の二値分類器の組み合わせ\n",
        "- 確率の正規化の重要性\n",
        "- 多クラス分類の評価方法\n",
        "\n",
        "**重要なポイント**：\n",
        "- One-vs-Restは実装が簡単で効率的\n",
        "- 確率の正規化が必要\n",
        "- クラス不均衡の影響を受けやすい\n",
        "- 決定境界が複雑になる場合がある\n",
        "\n",
        "**次のステップ**：\n",
        "- One-vs-Oneアプローチの学習\n",
        "- 多項ロジスティック回帰の実装\n",
        "- より高度な多クラス分類手法の学習\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
