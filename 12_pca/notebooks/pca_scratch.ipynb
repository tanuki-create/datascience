{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PCAのスクラッチ実装\n",
        "\n",
        "このノートブックでは、PCA（主成分分析）を一から実装し、理論を深く理解します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# PCAの手動実装\n",
        "def pca_manual(X, n_components=None):\n",
        "    # 1. データの標準化\n",
        "    X_centered = X - np.mean(X, axis=0)\n",
        "    \n",
        "    # 2. 共分散行列の計算\n",
        "    cov_matrix = np.cov(X_centered.T)\n",
        "    \n",
        "    # 3. 固有値・固有ベクトルの計算\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "    \n",
        "    # 4. 固有値の降順ソート\n",
        "    idx = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvalues = eigenvalues[idx]\n",
        "    eigenvectors = eigenvectors[:, idx]\n",
        "    \n",
        "    # 5. 主成分の選択\n",
        "    if n_components is not None:\n",
        "        eigenvectors = eigenvectors[:, :n_components]\n",
        "        eigenvalues = eigenvalues[:n_components]\n",
        "    \n",
        "    # 6. データの変換\n",
        "    X_transformed = X_centered @ eigenvectors\n",
        "    \n",
        "    return X_transformed, eigenvectors, eigenvalues\n",
        "\n",
        "# データの準備\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# データの標準化\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCAの適用\n",
        "X_pca, components, eigenvalues = pca_manual(X_scaled, n_components=2)\n",
        "\n",
        "# 可視化\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# 元データ（最初の2つの特徴量）\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap='viridis')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Original Data (First 2 Features)')\n",
        "\n",
        "# PCA後のデータ\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.title('PCA Transformed Data')\n",
        "\n",
        "# 寄与率\n",
        "plt.subplot(1, 3, 3)\n",
        "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
        "plt.bar(range(1, 5), explained_variance_ratio)\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Explained Variance Ratio')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=== PCAの手動実装結果 ===\")\n",
        "print(f\"固有値: {eigenvalues}\")\n",
        "print(f\"寄与率: {explained_variance_ratio}\")\n",
        "print(f\"累積寄与率: {np.cumsum(explained_variance_ratio)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
