{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 顔検出と認識\n",
    "\n",
    "このノートブックでは、顔検出と認識について学びます。\n",
    "\n",
    "## 目次\n",
    "1. [Haar Cascade](#haar-cascade)\n",
    "2. [DNNベースの検出](#dnnベースの検出)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import filters, feature\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "np.random.seed(42)\n",
    "print(\"ライブラリのインポートが完了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haar Cascadeによる顔検出\n",
    "# OpenCVに含まれる事前学習済みモデルを使用\n",
    "\n",
    "# 注意: 実際の顔画像がないため、サンプル画像を作成\n",
    "# 実際の使用では、cv2.imread()で画像を読み込んでください\n",
    "\n",
    "# サンプル画像の作成（実際の顔画像の代わり）\n",
    "img = np.random.randint(0, 256, (400, 400, 3), dtype=np.uint8)\n",
    "\n",
    "# Haar Cascade分類器の読み込み\n",
    "# OpenCVに含まれる顔検出用の分類器\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# グレースケールに変換\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# 顔の検出\n",
    "# パラメータを調整可能\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,  # 画像スケールの縮小率\n",
    "    minNeighbors=5,   # 検出に必要な近傍矩形の数\n",
    "    minSize=(30, 30)  # 最小検出サイズ\n",
    ")\n",
    "\n",
    "# 検出された顔を描画\n",
    "img_faces = img.copy()\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img_faces, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.putText(img_faces, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# 結果の表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('元の画像')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_faces)\n",
    "axes[1].set_title(f'検出された顔 ({len(faces)}個)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"検出された顔の数: {len(faces)}\")\n",
    "print(\"\\nHaar Cascadeのパラメータ:\")\n",
    "print(\"- scaleFactor: 画像スケールの縮小率（通常1.1-1.3）\")\n",
    "print(\"- minNeighbors: 検出に必要な近傍矩形の数（高いほど厳格）\")\n",
    "print(\"- minSize: 検出する最小サイズ\")\n",
    "print(\"- maxSize: 検出する最大サイズ（オプション）\")\n",
    "print(\"\\n注意: 実際の顔画像でテストしてください。\")\n",
    "print(\"使用例: faces = face_cascade.detectMultiScale(gray, 1.1, 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNNベースの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN（Deep Neural Network）ベースの顔検出\n",
    "# OpenCV DNNモジュールを使用した高精度な顔検出\n",
    "\n",
    "# 注意: 事前学習済みモデルファイルが必要です\n",
    "# 以下のモデルが利用可能:\n",
    "# - OpenCV Face Detector (YUNet)\n",
    "# - MTCNN\n",
    "# - Dlib\n",
    "\n",
    "print(\"=== DNNベースの顔検出 ===\")\n",
    "print(\"\\n利用可能なモデル:\")\n",
    "print(\"1. OpenCV Face Detector (YUNet)\")\n",
    "print(\"   - 高速で高精度\")\n",
    "print(\"   - OpenCV 4.5.1以降で利用可能\")\n",
    "print(\"\\n2. MTCNN (Multi-task CNN)\")\n",
    "print(\"   - 顔検出とランドマーク検出\")\n",
    "print(\"   - より高精度だが遅い\")\n",
    "print(\"\\n3. Dlib HOG + Linear SVM\")\n",
    "print(\"   - バランスの取れた性能\")\n",
    "print(\"\\n実装例（YUNet）:\")\n",
    "\n",
    "# YUNetモデルの使用例（モデルファイルが必要）\n",
    "# detector = cv2.FaceDetectorYN.create(\n",
    "#     \"face_detection_yunet_2022mar.onnx\",\n",
    "#     \"\",\n",
    "#     (320, 320),\n",
    "#     0.9,  # score_threshold\n",
    "#     0.3,  # nms_threshold\n",
    "#     5000  # top_k\n",
    "# )\n",
    "# detector.setInputSize((img.shape[1], img.shape[0]))\n",
    "# _, faces = detector.detect(img)\n",
    "\n",
    "print(\"\\nコード例:\")\n",
    "print(\"\"\"\n",
    "# YUNetモデルの読み込み\n",
    "detector = cv2.FaceDetectorYN.create(\n",
    "    \"face_detection_yunet_2022mar.onnx\",\n",
    "    \"\",\n",
    "    (320, 320),\n",
    "    0.9, 0.3, 5000\n",
    ")\n",
    "\n",
    "# 顔検出\n",
    "detector.setInputSize((img.shape[1], img.shape[0]))\n",
    "_, faces = detector.detect(img)\n",
    "\n",
    "# 結果の描画\n",
    "for face in faces:\n",
    "    x, y, w, h = face[0:4].astype(int)\n",
    "    confidence = face[14]\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n=== モデルの比較 ===\")\n",
    "print(\"Haar Cascade:\")\n",
    "print(\"  - メリット: 軽量、高速、実装が簡単\")\n",
    "print(\"  - デメリット: 精度が低い、照明条件に敏感\")\n",
    "print(\"\\nDNNベース:\")\n",
    "print(\"  - メリット: 高精度、様々な条件に対応\")\n",
    "print(\"  - デメリット: 計算コストが高い、モデルファイルが必要\")\n",
    "print(\"\\n推奨:\")\n",
    "print(\"  - リアルタイム処理: Haar Cascade\")\n",
    "print(\"  - 高精度が必要: DNNベース（YUNet、MTCNN）\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
