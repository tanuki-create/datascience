# モデル評価

## 目次
1. [モデル評価とは](#モデル評価とは)
2. [汎化性能と過学習](#汎化性能と過学習)
3. [Hold-out法](#hold-out法)
4. [交差検証](#交差検証)
5. [Bias-Variance Tradeoff](#bias-variance-tradeoff)
6. [パイプライン](#パイプライン)
7. [実装の比較](#実装の比較)
8. [まとめ](#まとめ)

## モデル評価とは

### 定義
モデル評価（Model Evaluation）は、**構築した機械学習モデルの性能を客観的に測定し、汎化能力を評価する**プロセスです。適切な評価により、モデルの信頼性と実用性を判断できます。

### モデル評価の重要性

1. **汎化性能の確認**: 未知のデータに対する予測性能
2. **過学習の検出**: 訓練データに過度に適合した状態の回避
3. **モデル選択**: 複数のモデルから最適なものを選択
4. **ハイパーパラメータ調整**: 最適なパラメータの決定

### 評価の基本概念

#### 訓練データ vs テストデータ
- **訓練データ**: モデルの学習に使用
- **テストデータ**: モデルの性能評価に使用
- **検証データ**: ハイパーパラメータ調整に使用

#### 評価指標の選択
- **回帰**: MSE, RMSE, MAE, R²
- **分類**: 精度, 適合率, 再現率, F1スコア

## 汎化性能と過学習

### 汎化性能の定義

**汎化性能**は、モデルが**未知のデータに対してどれだけ正確に予測できるか**を表します。

### 過学習とは

**過学習（Overfitting）**は、モデルが訓練データに過度に適合し、**汎化性能が低下する**現象です。

### 過学習の特徴

#### 1. 訓練誤差とテスト誤差の乖離
- 訓練誤差: 非常に小さい
- テスト誤差: 大きい
- 差が大きいほど過学習が深刻

#### 2. 複雑すぎるモデル
- パラメータ数が多すぎる
- 特徴量数が多すぎる
- 非線形性が強すぎる

#### 3. データ不足
- サンプル数が少ない
- 特徴量に対してデータが不足

### 過学習の検出方法

#### 1. 学習曲線の分析
```
訓練誤差 vs テスト誤差
```

#### 2. 交差検証の活用
- 複数の分割で性能を確認
- 性能のばらつきを分析

#### 3. 正則化の効果
- 正則化パラメータの調整
- 性能の変化を観察

### 過学習の対策

#### 1. データの増加
- より多くのデータを収集
- データ拡張（Data Augmentation）

#### 2. 特徴量の削減
- 特徴選択
- 次元削減（PCA等）

#### 3. 正則化
- L1正則化（Lasso）
- L2正則化（Ridge）
- Elastic Net

#### 4. 早期停止
- 検証誤差が増加し始めたら学習を停止

## Hold-out法

### 基本概念

**Hold-out法**は、データを**訓練用とテスト用に分割**してモデルを評価する最もシンプルな手法です。

### データ分割の方法

#### 1. 基本的な分割
```
全データ → 訓練データ（70%）+ テストデータ（30%）
```

#### 2. 3分割の場合
```
全データ → 訓練データ（60%）+ 検証データ（20%）+ テストデータ（20%）
```

### 分割の注意点

#### 1. ランダム分割
- データの順序に依存しない
- 代表性を保つ

#### 2. 層化分割
- カテゴリ変数の分布を保持
- 各分割で同じ分布を維持

#### 3. 時系列データ
- 時間順序を考慮
- 未来のデータでテスト

### Hold-out法の利点

1. **実装が簡単**: 基本的な分割のみ
2. **計算量が少ない**: 1回の学習・評価
3. **理解しやすい**: 直感的な手法

### Hold-out法の制約

1. **データの無駄**: テストデータが学習に使用されない
2. **性能のばらつき**: 分割に依存する
3. **小データセット**: 十分なデータがない場合に不適

### 実装例

```python
from sklearn.model_selection import train_test_split

# 基本的な分割
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 層化分割
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
```

## 交差検証

### 基本概念

**交差検証（Cross Validation）**は、データを複数の分割で学習・評価し、**より信頼性の高い性能評価**を行う手法です。

### 交差検証の種類

#### 1. k-Fold交差検証

**k-Fold交差検証**は、データをk個の分割に分け、各分割をテストデータとして使用します。

**アルゴリズム**:
1. データをk個の等しいサイズの分割に分ける
2. 各分割を1回ずつテストデータとして使用
3. 残りのk-1個の分割で学習
4. k回の性能評価の平均を計算

**kの選択**:
- **k=5**: 一般的な選択
- **k=10**: より信頼性が高い
- **k=n**: Leave-One-Out交差検証（LOOCV）

#### 2. Leave-One-Out交差検証（LOOCV）

**LOOCV**は、各サンプルを1つずつテストデータとして使用する手法です。

**特徴**:
- k=n（サンプル数）
- 最も信頼性が高い
- 計算量が大きい

#### 3. 層化k-Fold交差検証

**層化k-Fold**は、各分割でカテゴリの分布を保持する手法です。

**適用場面**:
- 分類問題
- 不均衡データ
- カテゴリ変数を含むデータ

### 交差検証の利点

1. **信頼性の向上**: 複数の評価による安定性
2. **データの有効活用**: 全データを学習・評価に使用
3. **過学習の検出**: 性能のばらつきで判断
4. **ハイパーパラメータ調整**: 検証データとして活用

### 交差検証の制約

1. **計算量の増加**: k倍の計算が必要
2. **時間の増加**: 学習時間がk倍
3. **メモリ使用量**: 複数のモデルを保持

### 実装例

```python
from sklearn.model_selection import cross_val_score, KFold

# k-Fold交差検証
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=kfold)

# 層化k-Fold交差検証
from sklearn.model_selection import StratifiedKFold
skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=skfold)
```

## Bias-Variance Tradeoff

### 基本概念

**Bias-Variance Tradeoff**は、モデルの**バイアス（偏り）とバリアンス（分散）の間のトレードオフ**を表す重要な概念です。

### 誤差の分解

#### 総誤差の分解
```
E[(y - ŷ)²] = Bias² + Variance + Noise
```

ここで：
- **Bias²**: バイアスの二乗（系統的誤差）
- **Variance**: バリアンス（ランダム誤差）
- **Noise**: ノイズ（測定誤差）

#### 各成分の意味

**バイアス（Bias）**:
- モデルの**系統的な偏り**
- 真の関数との平均的な差
- 高バイアス = 学習不足（Underfitting）

**バリアンス（Variance）**:
- モデルの**予測のばらつき**
- データの変化に対する敏感さ
- 高バリアンス = 過学習（Overfitting）

**ノイズ（Noise）**:
- データに含まれる**測定誤差**
- モデルでは制御不可能
- 削減不可能な誤差

### Bias-Variance Tradeoffの可視化

#### 1. バイアス-バリアンス図
- 横軸: モデルの複雑さ
- 縦軸: 誤差
- バイアス: 減少傾向
- バリアンス: 増加傾向

#### 2. 最適な複雑さ
- バイアスとバリアンスの合計が最小
- 過学習と学習不足のバランス

### 実践的な対処法

#### 高バイアス（学習不足）の場合
1. **モデルの複雑化**
   - 特徴量の追加
   - 非線形モデルの使用
   - 深いモデルの構築

2. **正則化の緩和**
   - 正則化パラメータの減少
   - 制約の緩和

#### 高バリアンス（過学習）の場合
1. **モデルの単純化**
   - 特徴量の削減
   - 線形モデルの使用
   - 浅いモデルの構築

2. **正則化の強化**
   - 正則化パラメータの増加
   - 制約の強化

3. **データの増加**
   - より多くのデータを収集
   - データ拡張

### 診断方法

#### 1. 学習曲線の分析
```
訓練誤差 vs テスト誤差
```

#### 2. 交差検証の活用
```
CV誤差の平均と標準偏差
```

#### 3. 正則化パラメータの調整
```
正則化強度 vs 性能
```

## パイプライン

### 基本概念

**パイプライン**は、**データ前処理からモデル学習、評価までを一連の流れとして管理**する手法です。

### パイプラインの構成要素

#### 1. データ前処理
- 欠損値処理
- 特徴量スケーリング
- 特徴選択
- エンコーディング

#### 2. モデル学習
- アルゴリズムの選択
- ハイパーパラメータ調整
- 学習の実行

#### 3. 評価
- 性能指標の計算
- 可視化
- 結果の解釈

### パイプラインの利点

1. **再現性**: 同じ手順で結果を再現
2. **保守性**: 各ステップの独立性
3. **効率性**: 自動化による効率化
4. **デバッグ**: 問題の特定が容易

### 実装例

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression

# パイプラインの構築
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

# パイプラインの実行
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
```

### 交差検証との組み合わせ

```python
from sklearn.model_selection import cross_val_score

# パイプラインの交差検証
scores = cross_val_score(pipeline, X, y, cv=5)
print(f"CV Score: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")
```

## 実装の比較

### 評価手法の選択基準

| 手法 | データサイズ | 計算量 | 信頼性 | 実装の複雑さ |
|------|-------------|--------|--------|-------------|
| Hold-out | 大 | 小 | 中 | 簡単 |
| k-Fold CV | 中 | 中 | 高 | 中程度 |
| LOOCV | 小 | 大 | 最高 | 中程度 |
| 層化k-Fold | 中 | 中 | 高 | 中程度 |

### 実装時の注意点

#### 1. データリークの回避
- 前処理での情報漏洩
- 未来の情報の使用
- テストデータの混入

#### 2. 適切な分割
- ランダム性の確保
- 代表性の保持
- 時系列データの考慮

#### 3. 評価指標の選択
- 問題に適した指標
- 複数指標の併用
- ビジネス指標との関連

### 実装のベストプラクティス

#### 1. 段階的な評価
```
1. 単純なモデルでベースライン
2. 複雑なモデルで改善
3. ハイパーパラメータ調整
4. 最終評価
```

#### 2. 可視化の活用
```
1. 学習曲線
2. 残差プロット
3. 特徴量重要度
4. 予測結果の分布
```

#### 3. ドキュメント化
```
1. 評価手順の記録
2. 結果の解釈
3. 改善点の特定
4. 次のステップの計画
```

## まとめ

### モデル評価の重要性

モデル評価は機械学習プロジェクトの成功に不可欠です。適切な評価により、モデルの信頼性と実用性を確保できます。

### 主要な手法

- **Hold-out法**: シンプルで基本的な評価
- **交差検証**: より信頼性の高い評価
- **Bias-Variance Tradeoff**: モデルの特性理解
- **パイプライン**: 効率的な評価プロセス

### 実践的なポイント

1. **適切な分割**: データの特性を考慮
2. **複数指標**: 様々な角度からの評価
3. **可視化**: 結果の直感的な理解
4. **継続的改善**: 評価結果に基づく改善

### 次のステップ

- [評価指標](../05_metrics/05_evaluation_metrics.md)
- [非線形回帰](../06_nonlinear_regression/06_nonlinear_regression.md)
- [総まとめ](../07_summary/07_comprehensive_summary.md)

---

**関連ノートブック**:
- [Hold-out法](./notebooks/holdout_validation.ipynb)
- [LOOCV](./notebooks/loocv_implementation.ipynb)
- [k-Fold CV](./notebooks/kfold_cv_implementation.ipynb)
- [Pipeline](./notebooks/pipeline_cv_scaling.ipynb)
