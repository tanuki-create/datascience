{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 並行処理と並列処理の基本\n",
        "\n",
        "このノートブックでは、並行処理と並列処理の基本的な操作とベストプラクティスを学びます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# threadingでI/Oバウンドな処理を並行化する\n",
        "\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# 悪い例（逐次処理）\n",
        "def fetch_urls_sequential(urls):\n",
        "    \"\"\"URLを逐次取得\"\"\"\n",
        "    results = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            response = requests.get(url, timeout=5)\n",
        "            results.append(f\"{url}: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            results.append(f\"{url}: Error - {e}\")\n",
        "    return results\n",
        "\n",
        "# 良い例（並行処理）\n",
        "def fetch_single_url(url):\n",
        "    \"\"\"単一URLを取得\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        return f\"{url}: {response.status_code}\"\n",
        "    except Exception as e:\n",
        "        return f\"{url}: Error - {e}\"\n",
        "\n",
        "def fetch_urls_parallel(urls):\n",
        "    \"\"\"URLを並行取得\"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        results = list(executor.map(fetch_single_url, urls))\n",
        "    return results\n",
        "\n",
        "# 使用例\n",
        "urls = [\n",
        "    \"https://httpbin.org/delay/1\",\n",
        "    \"https://httpbin.org/delay/2\",\n",
        "    \"https://httpbin.org/delay/1\",\n",
        "    \"https://httpbin.org/delay/3\"\n",
        "]\n",
        "\n",
        "print(\"=== URL取得の比較 ===\")\n",
        "\n",
        "# 逐次処理\n",
        "start_time = time.time()\n",
        "sequential_results = fetch_urls_sequential(urls)\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"逐次処理時間: {sequential_time:.2f}秒\")\n",
        "print(f\"結果: {sequential_results}\")\n",
        "\n",
        "# 並行処理\n",
        "start_time = time.time()\n",
        "parallel_results = fetch_urls_parallel(urls)\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"\\n並行処理時間: {parallel_time:.2f}秒\")\n",
        "print(f\"結果: {parallel_results}\")\n",
        "print(f\"時間短縮: {sequential_time - parallel_time:.2f}秒\")\n",
        "\n",
        "# ファイル処理の並行化\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class FileProcessor:\n",
        "    \"\"\"ファイル処理クラス\"\"\"\n",
        "    \n",
        "    def __init__(self, max_workers=4):\n",
        "        self.max_workers = max_workers\n",
        "        self.results = []\n",
        "        self.lock = threading.Lock()\n",
        "    \n",
        "    def process_file(self, file_path):\n",
        "        \"\"\"単一ファイルを処理\"\"\"\n",
        "        try:\n",
        "            # ファイル処理をシミュレート\n",
        "            with open(file_path, 'r') as f:\n",
        "                content = f.read()\n",
        "            \n",
        "            # 処理時間をシミュレート\n",
        "            time.sleep(0.1)\n",
        "            \n",
        "            result = {\n",
        "                'file': str(file_path),\n",
        "                'size': len(content),\n",
        "                'lines': len(content.split('\\n')),\n",
        "                'status': 'success'\n",
        "            }\n",
        "            \n",
        "            with self.lock:\n",
        "                self.results.append(result)\n",
        "            \n",
        "            return result\n",
        "        except Exception as e:\n",
        "            error_result = {\n",
        "                'file': str(file_path),\n",
        "                'error': str(e),\n",
        "                'status': 'error'\n",
        "            }\n",
        "            with self.lock:\n",
        "                self.results.append(error_result)\n",
        "            return error_result\n",
        "    \n",
        "    def process_files_sequential(self, file_paths):\n",
        "        \"\"\"ファイルを逐次処理\"\"\"\n",
        "        self.results = []\n",
        "        for file_path in file_paths:\n",
        "            self.process_file(file_path)\n",
        "        return self.results\n",
        "    \n",
        "    def process_files_parallel(self, file_paths):\n",
        "        \"\"\"ファイルを並行処理\"\"\"\n",
        "        self.results = []\n",
        "        threads = []\n",
        "        \n",
        "        for file_path in file_paths:\n",
        "            thread = threading.Thread(target=self.process_file, args=(file_path,))\n",
        "            threads.append(thread)\n",
        "            thread.start()\n",
        "        \n",
        "        for thread in threads:\n",
        "            thread.join()\n",
        "        \n",
        "        return self.results\n",
        "\n",
        "# 使用例\n",
        "print(\"\\n=== ファイル処理の並行化 ===\")\n",
        "\n",
        "# テスト用ファイルを作成\n",
        "test_files = []\n",
        "for i in range(5):\n",
        "    file_path = f\"test_file_{i}.txt\"\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(f\"Test content for file {i}\\n\" * 10)\n",
        "    test_files.append(file_path)\n",
        "\n",
        "processor = FileProcessor()\n",
        "\n",
        "# 逐次処理\n",
        "start_time = time.time()\n",
        "sequential_results = processor.process_files_sequential(test_files)\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"逐次処理時間: {sequential_time:.2f}秒\")\n",
        "print(f\"処理されたファイル数: {len(sequential_results)}\")\n",
        "\n",
        "# 並行処理\n",
        "start_time = time.time()\n",
        "parallel_results = processor.process_files_parallel(test_files)\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"\\n並行処理時間: {parallel_time:.2f}秒\")\n",
        "print(f\"処理されたファイル数: {len(parallel_results)}\")\n",
        "print(f\"時間短縮: {sequential_time - parallel_time:.2f}秒\")\n",
        "\n",
        "# クリーンアップ\n",
        "for file_path in test_files:\n",
        "    os.remove(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# multiprocessingでCPUバウンドな処理を並列化する\n",
        "\n",
        "import multiprocessing\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "# CPUバウンドな処理\n",
        "def calculate_fibonacci(n):\n",
        "    \"\"\"フィボナッチ数を計算\"\"\"\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)\n",
        "\n",
        "def calculate_prime_numbers(max_num):\n",
        "    \"\"\"素数を計算\"\"\"\n",
        "    primes = []\n",
        "    for num in range(2, max_num):\n",
        "        is_prime = True\n",
        "        for i in range(2, int(math.sqrt(num)) + 1):\n",
        "            if num % i == 0:\n",
        "                is_prime = False\n",
        "                break\n",
        "        if is_prime:\n",
        "            primes.append(num)\n",
        "    return primes\n",
        "\n",
        "# 逐次処理\n",
        "def process_sequential(numbers):\n",
        "    \"\"\"逐次処理\"\"\"\n",
        "    results = []\n",
        "    for num in numbers:\n",
        "        result = calculate_fibonacci(num)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "# 並列処理\n",
        "def process_parallel(numbers):\n",
        "    \"\"\"並列処理\"\"\"\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        results = pool.map(calculate_fibonacci, numbers)\n",
        "    return results\n",
        "\n",
        "# 使用例\n",
        "print(\"=== CPUバウンドな処理の並列化 ===\")\n",
        "\n",
        "# テストデータ\n",
        "numbers = [30, 31, 32, 33, 34]\n",
        "\n",
        "# 逐次処理\n",
        "start_time = time.time()\n",
        "sequential_results = process_sequential(numbers)\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"逐次処理時間: {sequential_time:.2f}秒\")\n",
        "print(f\"結果: {sequential_results}\")\n",
        "\n",
        "# 並列処理\n",
        "start_time = time.time()\n",
        "parallel_results = process_parallel(numbers)\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"\\n並列処理時間: {parallel_time:.2f}秒\")\n",
        "print(f\"結果: {parallel_results}\")\n",
        "print(f\"時間短縮: {sequential_time - parallel_time:.2f}秒\")\n",
        "print(f\"スピードアップ: {sequential_time / parallel_time:.2f}x\")\n",
        "\n",
        "# 画像処理の並列化\n",
        "class ImageProcessor:\n",
        "    \"\"\"画像処理クラス\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.processed_count = 0\n",
        "        self.lock = multiprocessing.Lock()\n",
        "    \n",
        "    def process_single_image(self, image_data):\n",
        "        \"\"\"単一画像を処理\"\"\"\n",
        "        image_id, width, height = image_data\n",
        "        \n",
        "        # 画像処理をシミュレート\n",
        "        time.sleep(0.1)  # 処理時間をシミュレート\n",
        "        \n",
        "        # 簡単な画像処理をシミュレート\n",
        "        processed_pixels = width * height\n",
        "        brightness = random.uniform(0.5, 1.5)\n",
        "        contrast = random.uniform(0.8, 1.2)\n",
        "        \n",
        "        result = {\n",
        "            'image_id': image_id,\n",
        "            'processed_pixels': processed_pixels,\n",
        "            'brightness': brightness,\n",
        "            'contrast': contrast,\n",
        "            'status': 'completed'\n",
        "        }\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def process_images_sequential(self, image_data_list):\n",
        "        \"\"\"画像を逐次処理\"\"\"\n",
        "        results = []\n",
        "        for image_data in image_data_list:\n",
        "            result = self.process_single_image(image_data)\n",
        "            results.append(result)\n",
        "        return results\n",
        "    \n",
        "    def process_images_parallel(self, image_data_list):\n",
        "        \"\"\"画像を並列処理\"\"\"\n",
        "        with multiprocessing.Pool() as pool:\n",
        "            results = pool.map(self.process_single_image, image_data_list)\n",
        "        return results\n",
        "\n",
        "# 使用例\n",
        "print(\"\\n=== 画像処理の並列化 ===\")\n",
        "\n",
        "# テストデータ\n",
        "image_data_list = [\n",
        "    (i, 1920, 1080) for i in range(10)\n",
        "]\n",
        "\n",
        "processor = ImageProcessor()\n",
        "\n",
        "# 逐次処理\n",
        "start_time = time.time()\n",
        "sequential_results = processor.process_images_sequential(image_data_list)\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"逐次処理時間: {sequential_time:.2f}秒\")\n",
        "print(f\"処理された画像数: {len(sequential_results)}\")\n",
        "\n",
        "# 並列処理\n",
        "start_time = time.time()\n",
        "parallel_results = processor.process_images_parallel(image_data_list)\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"\\n並列処理時間: {parallel_time:.2f}秒\")\n",
        "print(f\"処理された画像数: {len(parallel_results)}\")\n",
        "print(f\"時間短縮: {sequential_time - parallel_time:.2f}秒\")\n",
        "print(f\"スピードアップ: {sequential_time / parallel_time:.2f}x\")\n",
        "\n",
        "# データ分析の並列化\n",
        "import statistics\n",
        "\n",
        "def analyze_data_chunk(data_chunk):\n",
        "    \"\"\"データチャンクを分析\"\"\"\n",
        "    chunk_id, data = data_chunk\n",
        "    \n",
        "    # データ分析をシミュレート\n",
        "    time.sleep(0.05)  # 処理時間をシミュレート\n",
        "    \n",
        "    # 統計計算\n",
        "    mean_val = statistics.mean(data)\n",
        "    median_val = statistics.median(data)\n",
        "    std_val = statistics.stdev(data) if len(data) > 1 else 0\n",
        "    min_val = min(data)\n",
        "    max_val = max(data)\n",
        "    \n",
        "    result = {\n",
        "        'chunk_id': chunk_id,\n",
        "        'count': len(data),\n",
        "        'mean': mean_val,\n",
        "        'median': median_val,\n",
        "        'std': std_val,\n",
        "        'min': min_val,\n",
        "        'max': max_val\n",
        "    }\n",
        "    \n",
        "    return result\n",
        "\n",
        "def analyze_data_sequential(data_chunks):\n",
        "    \"\"\"データを逐次分析\"\"\"\n",
        "    results = []\n",
        "    for chunk in data_chunks:\n",
        "        result = analyze_data_chunk(chunk)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "def analyze_data_parallel(data_chunks):\n",
        "    \"\"\"データを並列分析\"\"\"\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        results = pool.map(analyze_data_chunk, data_chunks)\n",
        "    return results\n",
        "\n",
        "# 使用例\n",
        "print(\"\\n=== データ分析の並列化 ===\")\n",
        "\n",
        "# テストデータ\n",
        "data_chunks = [\n",
        "    (i, [random.uniform(0, 100) for _ in range(1000)]) \n",
        "    for i in range(20)\n",
        "]\n",
        "\n",
        "# 逐次処理\n",
        "start_time = time.time()\n",
        "sequential_results = analyze_data_sequential(data_chunks)\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"逐次処理時間: {sequential_time:.2f}秒\")\n",
        "print(f\"分析されたチャンク数: {len(sequential_results)}\")\n",
        "\n",
        "# 並列処理\n",
        "start_time = time.time()\n",
        "parallel_results = analyze_data_parallel(data_chunks)\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"\\n並列処理時間: {parallel_time:.2f}秒\")\n",
        "print(f\"分析されたチャンク数: {len(parallel_results)}\")\n",
        "print(f\"時間短縮: {sequential_time - parallel_time:.2f}秒\")\n",
        "print(f\"スピードアップ: {sequential_time / parallel_time:.2f}x\")\n",
        "\n",
        "# 結果の表示\n",
        "print(f\"\\n最初のチャンクの結果:\")\n",
        "result = parallel_results[0]\n",
        "print(f\"  チャンクID: {result['chunk_id']}\")\n",
        "print(f\"  データ数: {result['count']}\")\n",
        "print(f\"  平均: {result['mean']:.2f}\")\n",
        "print(f\"  中央値: {result['median']:.2f}\")\n",
        "print(f\"  標準偏差: {result['std']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# asyncioで非同期処理を効率的に管理する\n",
        "\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import time\n",
        "\n",
        "# 非同期関数の定義\n",
        "async def fetch_single_url(session, url):\n",
        "    \"\"\"単一URLを非同期取得\"\"\"\n",
        "    try:\n",
        "        async with session.get(url, timeout=5) as response:\n",
        "            return f\"{url}: {response.status}\"\n",
        "    except Exception as e:\n",
        "        return f\"{url}: Error - {e}\"\n",
        "\n",
        "async def fetch_urls_async(urls):\n",
        "    \"\"\"URLを非同期取得\"\"\"\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [fetch_single_url(session, url) for url in urls]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "    return results\n",
        "\n",
        "# 使用例\n",
        "print(\"=== 非同期処理の例 ===\")\n",
        "\n",
        "urls = [\n",
        "    \"https://httpbin.org/delay/1\",\n",
        "    \"https://httpbin.org/delay/2\",\n",
        "    \"https://httpbin.org/delay/1\",\n",
        "    \"https://httpbin.org/delay/3\"\n",
        "]\n",
        "\n",
        "# 非同期処理\n",
        "start_time = time.time()\n",
        "results = await fetch_urls_async(urls)\n",
        "async_time = time.time() - start_time\n",
        "print(f\"非同期処理時間: {async_time:.2f}秒\")\n",
        "print(f\"結果: {results}\")\n",
        "\n",
        "# ファイル処理の非同期化\n",
        "import aiofiles\n",
        "\n",
        "async def process_file_async(file_path):\n",
        "    \"\"\"単一ファイルを非同期処理\"\"\"\n",
        "    try:\n",
        "        async with aiofiles.open(file_path, 'r') as f:\n",
        "            content = await f.read()\n",
        "        \n",
        "        # 処理時間をシミュレート\n",
        "        await asyncio.sleep(0.1)\n",
        "        \n",
        "        result = {\n",
        "            'file': str(file_path),\n",
        "            'size': len(content),\n",
        "            'lines': len(content.split('\\n')),\n",
        "            'status': 'success'\n",
        "        }\n",
        "        \n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'file': str(file_path),\n",
        "            'error': str(e),\n",
        "            'status': 'error'\n",
        "        }\n",
        "\n",
        "async def process_files_async(file_paths):\n",
        "    \"\"\"ファイルを非同期処理\"\"\"\n",
        "    tasks = [process_file_async(file_path) for file_path in file_paths]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    return results\n",
        "\n",
        "# 使用例\n",
        "print(\"\\n=== ファイル処理の非同期化 ===\")\n",
        "\n",
        "# テスト用ファイルを作成\n",
        "test_files = []\n",
        "for i in range(5):\n",
        "    file_path = f\"test_file_{i}.txt\"\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(f\"Test content for file {i}\\n\" * 10)\n",
        "    test_files.append(file_path)\n",
        "\n",
        "# 非同期処理\n",
        "start_time = time.time()\n",
        "results = await process_files_async(test_files)\n",
        "async_time = time.time() - start_time\n",
        "print(f\"非同期処理時間: {async_time:.2f}秒\")\n",
        "print(f\"処理されたファイル数: {len(results)}\")\n",
        "\n",
        "# クリーンアップ\n",
        "for file_path in test_files:\n",
        "    os.remove(file_path)\n",
        "\n",
        "# データベース操作の非同期化\n",
        "import sqlite3\n",
        "import aiosqlite\n",
        "\n",
        "async def insert_user_async(db_path, name, email):\n",
        "    \"\"\"ユーザーを非同期挿入\"\"\"\n",
        "    async with aiosqlite.connect(db_path) as db:\n",
        "        await db.execute(\n",
        "            \"INSERT INTO users (name, email) VALUES (?, ?)\",\n",
        "            (name, email)\n",
        "        )\n",
        "        await db.commit()\n",
        "\n",
        "async def insert_users_async(db_path, user_data):\n",
        "    \"\"\"ユーザーを非同期挿入\"\"\"\n",
        "    tasks = [insert_user_async(db_path, name, email) for name, email in user_data]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "# 使用例\n",
        "print(\"\\n=== データベース操作の非同期化 ===\")\n",
        "\n",
        "# データベースを初期化\n",
        "async def init_database():\n",
        "    async with aiosqlite.connect(\"test_async.db\") as db:\n",
        "        await db.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                name TEXT,\n",
        "                email TEXT,\n",
        "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "        await db.commit()\n",
        "\n",
        "# テストデータ\n",
        "user_data = [\n",
        "    (f\"User{i}\", f\"user{i}@example.com\") for i in range(20)\n",
        "]\n",
        "\n",
        "# データベースを初期化\n",
        "await init_database()\n",
        "\n",
        "# 非同期処理\n",
        "start_time = time.time()\n",
        "await insert_users_async(\"test_async.db\", user_data)\n",
        "async_time = time.time() - start_time\n",
        "print(f\"非同期処理時間: {async_time:.2f}秒\")\n",
        "\n",
        "# ユーザー数を確認\n",
        "async with aiosqlite.connect(\"test_async.db\") as db:\n",
        "    async with db.execute(\"SELECT COUNT(*) FROM users\") as cursor:\n",
        "        count = await cursor.fetchone()\n",
        "        print(f\"ユーザー数: {count[0]}\")\n",
        "\n",
        "# クリーンアップ\n",
        "os.remove(\"test_async.db\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
