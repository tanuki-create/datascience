{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Precision-Recall Tradeoff\n",
        "\n",
        "このノートブックでは、PrecisionとRecallのトレードオフ関係を詳しく学習し、実務での活用方法を理解します。\n",
        "\n",
        "## 学習目標\n",
        "- Precision-Recall tradeoffの理論的理解\n",
        "- 閾値の調整による指標の変化\n",
        "- 実務での最適な閾値の選択\n",
        "- Precision-Recall曲線の解釈\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (precision_recall_curve, precision_score, recall_score,\n",
        "                           f1_score, average_precision_score, classification_report)\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 日本語フォントの設定\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "sns.set_style(\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Precision-Recall Tradeoffの基本概念\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_precision_recall_manual(y_true, y_pred_proba, thresholds):\n",
        "    \"\"\"\n",
        "    Precision-Recall曲線の手動実装\n",
        "    \n",
        "    Parameters:\n",
        "    y_true: 実際のラベル\n",
        "    y_pred_proba: 予測確率\n",
        "    thresholds: 閾値のリスト\n",
        "    \n",
        "    Returns:\n",
        "    results: 各閾値でのPrecisionとRecall\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        \n",
        "        # 混同行列の計算\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "        \n",
        "        # PrecisionとRecallの計算\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        \n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 簡単な例でPrecision-Recall tradeoffを理解\n",
        "np.random.seed(42)\n",
        "y_true_example = np.random.binomial(1, 0.3, 100)\n",
        "y_pred_proba_example = np.random.beta(2, 5, 100)\n",
        "\n",
        "# 異なる閾値での評価\n",
        "thresholds_example = np.arange(0.1, 1.0, 0.05)\n",
        "results_example = calculate_precision_recall_manual(y_true_example, y_pred_proba_example, thresholds_example)\n",
        "\n",
        "# 結果の可視化\n",
        "df_example = pd.DataFrame(results_example)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Precision vs Threshold\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(df_example['threshold'], df_example['precision'], 'o-', color='blue', label='Precision')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "# Recall vs Threshold\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(df_example['threshold'], df_example['recall'], 'o-', color='red', label='Recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "# Precision vs Recall\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(df_example['recall'], df_example['precision'], 'o-', color='green', label='PR Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs Recall')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=== Precision-Recall Tradeoffの基本概念 ===\")\n",
        "print(\"Precision: 正例と予測したもののうち、実際に正例だった割合\")\n",
        "print(\"Recall: 実際の正例のうち、正しく正例と予測できた割合\")\n",
        "print(\"\\nトレードオフの関係:\")\n",
        "print(\"- 閾値を下げる → Recall ↑, Precision ↓\")\n",
        "print(\"- 閾値を上げる → Precision ↑, Recall ↓\")\n",
        "print(\"- 理想: 両方とも高い値\")\n",
        "print(\"- 現実: 一方を上げると他方が下がる\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 実データでのPrecision-Recall曲線\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 乳がんデータセットでのPrecision-Recall曲線\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# データの分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ロジスティック回帰モデルの訓練\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 予測確率\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Precision-Recall曲線の計算\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "average_precision = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "# 可視化\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Precision-Recall曲線\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(recall, precision, 'b-', linewidth=2, label=f'PR Curve (AP = {average_precision:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Precision vs Threshold\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(thresholds, precision[:-1], 'b-', linewidth=2, label='Precision')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Recall vs Threshold\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(thresholds, recall[:-1], 'r-', linewidth=2, label='Recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall vs Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=== 乳がんデータセットでのPrecision-Recall曲線 ===\")\n",
        "print(f\"Average Precision: {average_precision:.4f}\")\n",
        "print(f\"データセットの情報:\")\n",
        "print(f\"  サンプル数: {len(y_test)}\")\n",
        "print(f\"  クラス分布: {np.bincount(y_test)}\")\n",
        "print(f\"  正例の割合: {np.mean(y_test):.2%}\")\n",
        "\n",
        "# 異なる閾値での性能\n",
        "def evaluate_threshold_performance(y_true, y_pred_proba, thresholds):\n",
        "    \"\"\"\n",
        "    異なる閾値での性能評価\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        \n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        \n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 異なる閾値での評価\n",
        "thresholds_eval = np.arange(0.1, 1.0, 0.1)\n",
        "results_eval = evaluate_threshold_performance(y_test, y_pred_proba, thresholds_eval)\n",
        "\n",
        "# 結果の表示\n",
        "df_eval = pd.DataFrame(results_eval)\n",
        "print(f\"\\n=== 異なる閾値での性能 ===\")\n",
        "print(df_eval.round(4))\n",
        "\n",
        "# 最適な閾値の選択\n",
        "best_f1_idx = df_eval['f1'].idxmax()\n",
        "best_threshold = df_eval.loc[best_f1_idx, 'threshold']\n",
        "best_f1 = df_eval.loc[best_f1_idx, 'f1']\n",
        "\n",
        "print(f\"\\n最適なF1-score: {best_f1:.4f} (閾値: {best_threshold:.1f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 実務での閾値選択\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 実務での閾値選択戦略\n",
        "def find_optimal_threshold(y_true, y_pred_proba, strategy='f1'):\n",
        "    \"\"\"\n",
        "    実務での最適な閾値の選択\n",
        "    \n",
        "    Parameters:\n",
        "    y_true: 実際のラベル\n",
        "    y_pred_proba: 予測確率\n",
        "    strategy: 選択戦略 ('f1', 'precision', 'recall', 'balanced')\n",
        "    \n",
        "    Returns:\n",
        "    optimal_threshold: 最適な閾値\n",
        "    \"\"\"\n",
        "    thresholds = np.arange(0.1, 1.0, 0.01)\n",
        "    results = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        \n",
        "        precision = precision_score(y_true, y_pred)\n",
        "        recall = recall_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        \n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    if strategy == 'f1':\n",
        "        optimal_idx = df['f1'].idxmax()\n",
        "    elif strategy == 'precision':\n",
        "        optimal_idx = df['precision'].idxmax()\n",
        "    elif strategy == 'recall':\n",
        "        optimal_idx = df['recall'].idxmax()\n",
        "    elif strategy == 'balanced':\n",
        "        # PrecisionとRecallのバランスを取る\n",
        "        df['balance'] = np.abs(df['precision'] - df['recall'])\n",
        "        optimal_idx = df['balance'].idxmin()\n",
        "    \n",
        "    return df.loc[optimal_idx, 'threshold'], df.loc[optimal_idx]\n",
        "\n",
        "# 異なる戦略での最適な閾値\n",
        "strategies = ['f1', 'precision', 'recall', 'balanced']\n",
        "optimal_thresholds = {}\n",
        "\n",
        "for strategy in strategies:\n",
        "    threshold, metrics = find_optimal_threshold(y_test, y_pred_proba, strategy)\n",
        "    optimal_thresholds[strategy] = {\n",
        "        'threshold': threshold,\n",
        "        'precision': metrics['precision'],\n",
        "        'recall': metrics['recall'],\n",
        "        'f1': metrics['f1']\n",
        "    }\n",
        "\n",
        "# 結果の可視化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 各戦略の比較\n",
        "strategies_data = []\n",
        "for strategy, data in optimal_thresholds.items():\n",
        "    strategies_data.append({\n",
        "        'Strategy': strategy,\n",
        "        'Threshold': data['threshold'],\n",
        "        'Precision': data['precision'],\n",
        "        'Recall': data['recall'],\n",
        "        'F1': data['f1']\n",
        "    })\n",
        "\n",
        "df_strategies = pd.DataFrame(strategies_data)\n",
        "\n",
        "# 閾値の比較\n",
        "axes[0, 0].bar(df_strategies['Strategy'], df_strategies['Threshold'], color='skyblue')\n",
        "axes[0, 0].set_title('Optimal Thresholds by Strategy')\n",
        "axes[0, 0].set_ylabel('Threshold')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Precisionの比較\n",
        "axes[0, 1].bar(df_strategies['Strategy'], df_strategies['Precision'], color='lightcoral')\n",
        "axes[0, 1].set_title('Precision by Strategy')\n",
        "axes[0, 1].set_ylabel('Precision')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Recallの比較\n",
        "axes[1, 0].bar(df_strategies['Strategy'], df_strategies['Recall'], color='lightgreen')\n",
        "axes[1, 0].set_title('Recall by Strategy')\n",
        "axes[1, 0].set_ylabel('Recall')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# F1-scoreの比較\n",
        "axes[1, 1].bar(df_strategies['Strategy'], df_strategies['F1'], color='gold')\n",
        "axes[1, 1].set_title('F1-score by Strategy')\n",
        "axes[1, 1].set_ylabel('F1-score')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=== 実務での閾値選択戦略 ===\")\n",
        "print(df_strategies.round(4))\n",
        "\n",
        "# 実務での解釈\n",
        "print(\"\\n=== 実務での解釈 ===\")\n",
        "print(\"医療診断:\")\n",
        "print(\"  - Recall重視: 病気の見逃しを避ける\")\n",
        "print(\"  - 低い閾値: より多くの患者を検査対象に\")\n",
        "\n",
        "print(\"\\nスパム判定:\")\n",
        "print(\"  - Precision重視: 重要なメールの誤判定を避ける\")\n",
        "print(\"  - 高い閾値: 確実なスパムのみを判定\")\n",
        "\n",
        "print(\"\\n推薦システム:\")\n",
        "print(\"  - F1-score重視: バランスの取れた性能\")\n",
        "print(\"  - 中程度の閾値: 精度と網羅性のバランス\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 演習問題\n",
        "\n",
        "### 演習1: 異なるデータセットでの分析\n",
        "クラス不均衡データでPrecision-Recall曲線を描画し、閾値の影響を観察してみましょう。\n",
        "\n",
        "### 演習2: カスタム戦略の実装\n",
        "ビジネス要件に応じたカスタム閾値選択戦略を実装してみましょう。\n",
        "\n",
        "### 演習3: 複数モデルの比較\n",
        "異なるモデルでのPrecision-Recall曲線を比較し、性能を評価してみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、Precision-Recall tradeoffについて詳しく学習しました。\n",
        "\n",
        "**学習した内容**：\n",
        "- Precision-Recall tradeoffの理論的理解\n",
        "- 閾値の調整による指標の変化\n",
        "- 実務での最適な閾値の選択戦略\n",
        "- Precision-Recall曲線の解釈\n",
        "\n",
        "**重要なポイント**：\n",
        "- PrecisionとRecallはトレードオフの関係\n",
        "- 実務では目的に応じた閾値選択が重要\n",
        "- 複数の戦略を比較して最適解を見つける\n",
        "- 可視化により直感的な理解が可能\n",
        "\n",
        "**次のステップ**：\n",
        "- ROC曲線とAUCの学習\n",
        "- 多クラス分類の評価指標\n",
        "- より高度な評価手法の学習\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
